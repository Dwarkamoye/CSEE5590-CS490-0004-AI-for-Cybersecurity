{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dwarkamoye/CSEE5590-CS490-0004-AI-for-Cybersecurity/blob/master/LAB-2-Assignment/Membership_Attack_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "ac50e752-88ee-4d08-b11d-5aae5d26c3c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/UMKC/Cybersecurity/ICP-66'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "75838c53-964f-4020-9a7c-205048204050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "869a3697-aaab-4538-82af-d172a835c6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "\n",
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "truck horse  deer  frog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noTs4ODhMEPx/EQImmQRBgDIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "38946133-f272-4423-d738-7f28b08f392f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9eQCyuRWWM-",
        "colab_type": "code",
        "outputId": "67dae5e6-9099-4c0c-8620-a36a6f20caed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "451b2edf-d5f0-4d3b-a360-fab8da42d2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.829892563697932\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.490560549375651\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.306488379111985\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1742076767070213\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0671017455018086\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9896539186349\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9279613579859209\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8749482576042185\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8146692953641762\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7664461194744805\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7288840654903971\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6889111416800248\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6511131359259491\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6295178114720013\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5988540727254528\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5829868637825675\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5494550774659952\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5285549617427237\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.5103253931035776\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.48567267248164053\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "9ba88580-0ba5-4b96-826b-07dabaa4aa9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "50b2772a-2b0f-4830-93de-b7c1da361356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7742320038473514\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.450527744524924\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.2591394273673786\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.144299233718144\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0409687059690884\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9518346140146865\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8800166353697667\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8184171085962859\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7691366223956618\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.720034679412232\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6881188191759312\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6361272653464771\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6168363721340971\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.5713836423233342\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5467767882472871\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5242449167515616\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5014468759174466\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.4752123782749447\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.45132255262178383\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4182109953668874\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJWwptKhXBQI",
        "colab_type": "code",
        "outputId": "d5fafb77-e0b9-4b1b-9e2e-c01de26ccdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_-zX1sXDP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6ovDN6XGJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHCVk4ZHXG_S",
        "colab_type": "code",
        "outputId": "41084d41-a4fb-4ee0-f462-def74b2ab1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "\n",
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1.6096343e-01, 2.0131838e-02, 9.1600772e-03, 2.5047942e-03,\n",
            "       4.0859042e-04, 1.8536662e-04, 1.1671983e-03, 4.3601997e-04,\n",
            "       1.2039007e-02, 7.9300368e-01], dtype=float32), 1]\n",
            "[array([1.5025024e-04, 1.2733466e-02, 1.2821561e-03, 5.6735549e-02,\n",
            "       1.2458536e-04, 9.1879851e-01, 1.4342525e-03, 1.3816927e-03,\n",
            "       6.3315569e-03, 1.0277940e-03], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yd6aasbXM8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzXpRo2UDjo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vcaI6bhDngD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOQmKgJzXOw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te348jm_D13e",
        "colab_type": "code",
        "outputId": "94be2810-212a-45cb-93f1-354aac2618be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uM_e-vCD7r7",
        "colab_type": "code",
        "outputId": "0e272db0-109e-4a5c-9989-13a94cc828c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "\n",
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06934394825220108\n",
            "Training loss: 0.06933605826854705\n",
            "Training loss: 0.06932913708925247\n",
            "Training loss: 0.06933132906198501\n",
            "Training loss: 0.06932344482421875\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WiSQHQ47Mvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB6aobdD7PEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBycw5t3D_qu",
        "colab_type": "code",
        "outputId": "32c2b1b8-b5a5-41aa-d6f5-b8a37697c0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "if((tp+fp)!=0):\n",
        "  pre = tp/(tp+fp)\n",
        "if((tp+fn)!=0):\n",
        "  rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}