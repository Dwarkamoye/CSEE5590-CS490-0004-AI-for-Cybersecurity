{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack_dataset_change-2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dwarkamoye/CSEE5590-CS490-0004-AI-for-Cybersecurity/blob/master/LAB-2-Assignment/Dataset_Change/Membership_Attack_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wILc-UwCY8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nEceNQKCgU1",
        "colab_type": "code",
        "outputId": "5c30108b-c19a-42b1-bf4b-26bdd8db0b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/UMKC/Cybersecurity/ICP-66'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYJPUoF1CjLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJISV6deCo7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQQ5KkMjCuAp",
        "colab_type": "code",
        "outputId": "8e563c5a-ce53-4cba-95b0-8123a37197cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.STL10(root= project_path+'/data', \n",
        "                                        split='train' ,download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.STL10(root= project_path+'/data', \n",
        "                                        split='test',download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('whale', 'shark', 'roses', 'cans', 'oranges', 'lamp', 'table', 'butterfly', 'lion', 'house')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFWn_Kl6M5Cr",
        "colab_type": "code",
        "outputId": "9316f430-d19e-4a5e-94a8-a769452e6c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnX90W+WZ57+vFCEh7Ch2XBvFTtaJ\na/CGpAmpIYSmEMhAw89wWqDAtMPMspszO7NLZ7d7duhy5tDMzpmd7s522tmz0M1Ch7DlkJYMSwIE\nSsiQhkAIhAST4Dg4TowTV4lRLIS1Qq6Q3v3jee5930SyLf+UpTyfc3x0/d733vveH7p63uen0lpD\nEARBKH08xR6AIAiCMDHIC10QBKFMkBe6IAhCmSAvdEEQhDJBXuiCIAhlgrzQBUEQygR5oQuCIJQJ\n43qhK6XWKKWOKKWOKqUemqhBCYIgCKNHjTWwSCnlBfARgBsAnATwLoB7tdbtEzc8QRAEoVBmjGPb\nKwEc1VofAwCl1CYAawEM+UIPBoN61qxZ4zikIAjC+UckEolqrb80Ur/xvNDrAZyw/j8JYPlwG8ya\nNQvr1q0bxyEFQRDOP9avX/9xIf0m3SiqlFqnlNqnlNqXTCYn+3CCIAjnLeN5ofcCmGv938BtZ6G1\n3qC1btVatwaDwXEcThAEQRiO8bzQ3wXQrJSar5S6AMA9ALZOzLAEQRCE0TJmHbrW+gul1L8B8GsA\nXgA/11p/ONr9rF+/fqxDGD2N/Nk9dYccFj9/DuZZV2Utx3JXP/LII2f9n4pEzfIg7bCpqcltq6io\nAAAc6egwbZWVZ+0j1t/vLmeyWQDATzc+nnPsxpnV7vLK61YDAGYGaV/HDr7vrnvl0P6cbZcsmAcA\naP3GHW5b228TAABvdS0AIJ5M5Ywxm8m4bY4Ukk6n3bZ0hsYbDNBF9Xq97rpkivaXsi501kd7+c68\nUM4YR/tM+px9Wm2ZfB3zMK++gcbWfxoA0Pd5erjuLqHZZjl+hhecC5M9t/fUcO4z+eAPf+gud/Ln\nYmu9zNfz80Pruo2W8RhFobXeBmDbePYhCIIgTAzjeqFPJEsWNLjLN3+LpL5gyOe2tb31OgCgt4ek\nufpLGt11p6Ikne7e1TX8QbonYKATST7J/FL6CFiCY+qdkXe156097nJVNUnQ2YwR1RyDdGJgIKfN\nw9JswO931+3atWvIY7VcttBdzqRp284uuvbZrJEwA874rW2zfMxkMu62dfKsIV4ZoYaoWQe/eQbM\njnmcqTzSrCOY2yKyOybrgodYPpy3Kncfo6QwmTo/Pb0nz/o/fKFZjnw+9HauVG5TJMl8KL636XV3\nee1d1wEAGszESST0SUBC/wVBEMoEeaELgiCUCUVXuWx66mcAgOVXLHPbfDzLjg4Yv/U777sLALDr\nhWcBAE//r2fddbvbrSk6487K86g11j94OwDgkb+fhk45R+gjNXyvHA4eOuguX9J8CQAgHjfX5URP\nDwBjHAWAWIysrSk2GrZecYW7LjJoVDMOrvLDY+bNoS+R9baP1V7dx3vcdfnOYdFllwEAAh6jSolH\n+2jhSFueLZ1+3jxt+ch3VEf5k8dUecuqYfY19QynZgGAqpn0Gfts8scybhLHzXKaVC4v9JrnasU8\nMngvmdJBlTcioQuCIJQJRZfQ6+aT9e/gR21uW1WQJLBYzEhUaR/9mt9yB6UOSMTNb1FzF4m1T2z8\njduWTzJ3cCTzVVfOd9t2vnN8qO4lx8mTZGirq6tz2xxp3ZbafTwVcj5ramqG3a9j/OuLGvfGer6E\nvTwD6Po8d7ZkE24I0zFrjF/mNVevAAC0RcngHbcMt5V11N9vGUf9AWO8dfB6zpXajYUwk6XnyDYS\n59tHKZAYjwV2ill1223uciTyWwDAv50/J6ffhpOn3eX5DfTMOlJ77eQNrywRCV0QBKFMkBe6IAhC\nmVB0lQtSNEWvDBqjVyxJU/pQyDhjpzM0DX/hpecAAKu/+V13Xe9jfz2mQ5eTmiXgD7jLfaz26O0e\nXv0RGCQDop8NjttffbWgY3kCxoP4SAfFAHac+qigbSOsDqr0GeNsDatfWvyk8klljaot3EDxCX6f\nUZF4fTRex5gLAIEAnb/fnxsp6kSU5usPmOl+KZAewWg6nVhRZ7K9bn7/PQBAD4zKZR5/rmuow1DY\nsca//pAC0VexYR2glK/2vs53REIXBEEoE4ouoScdY91ZmXXJeOX1JdyWIBvumufRb3Jnu8kZsub2\nOwEAP3vsZbPfaRY1N9nELDfDQu1mKfeTJOJ4HlfFfLS1GQN2TdXIZqtGS2wIhUgK7zpqonqrGyjn\nTEWaOvost8SaIEnyHssoGvCRdJ3KWDtO0Q33seHTFzT9feyqmbayffodI2qytCT0UmKhtfwnS78K\nAHgz9YnbNi8wYr0GLLOWz1xCcnj7aTOzTteRVb4YEnrUWh7enWDqEAldEAShTJAXuiAIQplQdJXL\n3n0HAACHDkfctniMlAbNLY1u2+VLmwEALS00bQ5ZioW9e8kH+o8fvMdt+9ljmwAAyWH80cuJyXJP\nbq43KXg7e7v4WMa4mBhI5GxzLg0tS93lihCpaGIHO836GjJ8Br1k0ExnzNlU1ZBhPBK1J7icTMwy\nziJNOrtMmsZmJwlLs0HV7wtY/UvIobsMcFQSay01i1MNpz6nd35u4FgU1FUO33EYnAiK//obo/pp\n289lkAfNyyLGyea6PqIIbL/fyL6JBEVY+z3mebpkPmXV81spqS9dQsmCv3n/SgDAauvxmyxEQhcE\nQSgTRpTQlVI/B3ArgD6t9SJuqwbwS1DJiG4Ad2ut85RhGJlfbSJD5twK47p08/UtAIBrbjRZHhbM\nI2ls5346TGWFkbCamyiasPHGq922H/9k01iGU7IUWlBhtNjukA5r19zlLnOdCGze9mxOP4eL640M\n9sbuNwEAsdPGGOn30k78LF/4fcagWVHBM7KMKaqRTdK9z1hStj/A23BbxpLykaX9Zq18MG6k6PCe\nncIk4jwVdvadQoTYNmvZkfLbTd0W7HjpLQDArtd2AAAqYFxe+7pYGo9a1TJjzrNozwIdrwpHprdH\nRkb2Gr9xq452kCQfrDSzxp2v/RIAsH0jzUrDS1vddTd/+z4AwL3XmrThE2HYLURCfxLAmnPaHgKw\nQ2vdDGAH/y8IgiAUkREldK31LqVU4znNawGs4uWNAHYC+POxDGAuBw+1NBqp7GHOtZKysiGuWkQZ\nBP/8YXJRTKWNxNZYT9u++LwJjFn3r28BAGx47KWxDKvsCObJUJgsQPPeecwEDLU0kk5w+TI7Px5J\nMqd6yY6xu21vzj4OWW6OcS5zVxE0Ek88zrOuGqo5nrSHxbrwoM/IHpkgS1xe0zHEbohJ3jhhFbPw\nnPMJAL6c3C9Csdhmectuf+VdAMDgAN2/fqu04oHdFGbU82672SDO678wNjgTLEbPZvKsZ995Cmzb\nTyG5Te2HkgacGDTTu/Qg2XCCZ8ws0MPPWGWcNAh9J7vddU+8sR0A8GilmT3ULyZHzxvDYy/9MVYd\nep3W2rmCpwAMHeolCIIgTAnjNopqrTUAPdR6pdQ6pdQ+pdQ+p+SZIAiCMPGM1W3xtFIqrLWOKKXC\nAPqG6qi13gBgAwDMmTMn58VfHaSpz//Y0nPuqrPYeYim/vMe3wkAWHvfDe66dJbUNrfedqPb9uQv\nflHIeZw3FKJeyUfK2q6jmww//+WvTZTnVSuWAzjHCHkOp/uMAXTZ5aS2ifZZjwxv66hhTvdbUa8s\nBPgs42yQ3RAzWaNWqeQo0DS3ZVNGeHDMW2krR0w2O/5Q4uZGcsbr7KZpv202G22BknLkLzaZiM5d\ne6jmbe/H5tmJ9JDratJ2ST3hqPgso6XL9LqqKZhnLM0G94TlnuDj5623j65DFYxaKBSh59VnGVGd\n64F/ee+YxzRWCX0rgPt5+X4AW8Y8AkEQBGFCKMRt8RmQAbRGKXUSwCMA/gbAr5RSDwD4GMDdYx3A\ntj39I3cC8O+/fS0A4L9v+mMAwJ5Nxk8pzUaKF583udk8vvPLxd42+wRYVhyYJIlmwJJMtu95fZie\nRPhiY8CexwUuYEnIWZZk0k5Q0KBJKejlGYLPZxmKeFPbVdMxcno9dN8z1v6d2YPXKnARLMBBLths\njlnPyYGaW5rdtr4ISVzLGkk6i0TMiKI8eTifw5f+6t4rrf8cr+bJcrAtLpk853Vuy+f29/ELLi4T\nM9+lYGr816YQL5eh5P/V4z66IAiCMGGcX2KsIAhCGVP0XC6O+asyT5tN89LLeYlyizQ1GQNDe6+T\n+8XEWkWjpVkzcqzYU3tHmbBi0RVuWyxGqq3+fhPQ2/d5Yequ0VBlKX9uXE1qsqoqUz80zfkywlZb\nkI2h2RSpWkIV5t5Fo2Q8DVn79XFOloDfvsc0XQ1yfpcKmAIag1zsIp0yVymRJB/ii/KdxIU8rk4z\nHXYyz3jTB922fnZD7suTLyjE+6gPm2hCHxfViFg1NPs+yzeAciE6cpfzCFsBmuFvrP1cYwJSfouE\nLgiCUCYUXUJvriXpKWYZBAY+o1+twIVGbt/+GkVWPfn0c9xijFpXXU0ujINe4wo3+MnwbpDlTCqP\nMdTjoevceoXJJ7FtV2El50aHkYKjHBV6ca1J/x/vI7E2mzH3O85FTirY8OnxG2Oklw2aPo8RX/xs\n8A74TVQe0hwVyG6OX6RNf8c1zD5mMsbitRHkDWyTzSdfdgzpoHs2cd5H/JidLEYSx5xfOM9nrrHT\nZCw1z3rQP/YIUQeR0AVBEMoEeaELgiCUCUVXuXT2kdFo2QKjJoh+RtPmlGW0e27H0Aa8vYdyK85X\nVXnz9Dw/cJQeUSsCb3CQrm9NTW71wxYuYtHd2+22OX61ixeYCus+vqSRkyfdtoHPKdK3ZjYZOec1\nmHSgTr3YU73GgH1xLaUSPdFjVGJOulyvh46ZTRtjZIbH7RSuAIAsR4r6rAIDHpZNHNWSx0q+lXZS\n6lpqmKBbX3Ry1SB2fMD57JN+fjKyX3nccgEJ5tX/jQ6R0AVBEMqEokvoTgL5/ccmdq+xWO6vY4gr\nx8cHzw9Zqc/KoeJI5uk8pdeamyk1cSRiJOk0R1pWWRK9k8J2YMBIFa77FZfe8lnFKbLsophOGen6\nM5baa2tMgk5PgAtQ8AzAY40xzTlZkkmT7jSbpWP4g7n5Xbxc6CJoRZZG0wM55+7h/pMVuHjNIoqO\njcTMzLIzX3oS4bwmaBlFPd7qYXoWhkjogiAIZYK80AVBEMqEaaBymRxqamn68if3meo6f/mTkRNJ\n2abUUk8jFM9aKWQ5Xe2et/bk9OvtpfSe2axVo3MGXYlk0hgNE6yqGrSqo6c/d5JnkWwQtKI3o5wo\nq9dS5TjXtLrSGCg9fNiqOqoymbV8zjPODbHVMFyNKO0zqpx05ux+dnI2xwCasPaRdZYnUKQJWd+m\nA4dI1VI107RV8frYFxN3zGKxbvV8AMDXr13mth0t9S9MEUhbpnJfZvzR7SKhC4IglAllIaGHWAqK\nW3kxon0kIW15tT3PFkNTrkKGk0p34MzJnHX7Ozty2hp9JDnsOfT+sPttmU35cyKnSZLv6bGS+FeR\nS2oyYQyaM9nIGrIk6Aru50wQ0nag6wX8WWWkF59jALWihb1erikaZ4OtHUXKUcgzLYNtYJiCHGMl\nnkfyHrCeyXJypH3hI3KJPTnwltt2xU2LijWcEsZ6KoLjr3MrErogCEKZUEiBi7kAngIVgtYANmit\nf6qUqgbwSwCNALoB3K21jg21n7Ewz/Kz70mcvW7xpSaLXeti0pH+w+YIziXSky93I/G9dde6y23v\nfggA2HlgYjPENdWTe15zU9ht6+giibi7NzfnyuoVFMgT6zfnsv/I2LIi+qxf/4XNLQCA2hpzUbfv\n2XtWfzvkKJBHnGxtpLF1W0FBnWdo2c/H8lpznDOnSId/obWP7p5u2n+lka4rWGr3uGE4Roee5gAh\nvy3JcPbEAdsF85ypld+aAWS8rN+3JHRfxqlAMXX5Vcpp9hfk/DjBcHiEnsJw+KzQs+RgYpiehVGI\nhP4FgO9rrRcCuArAnyqlFgJ4CMAOrXUzgB38vyAIglAkRnyha60jWuv9vDwA4DCAegBrAWzkbhsB\n3DFZgxQEQRBGZlRGUaVUI4DLAewFUKe1dvQCp0AqmQklNswMJBIxU/BL72HXqc0v5fT7zj03uctP\nPb0VAOB30ql6TZTWG8OoWhY2m/wkYc5Fsugyamv/0OSR+YwH7PGY30l/NV2WqnCt27a8ho7bwhGX\nPq9RMbzwCql+FteaYzbPINVC5xdDq49sc0qFn9RRYWs63Lp8BQDgiV88PuQ+7CsQ5Wu/cLalpuBI\nW5/lmvj1SxYDACor6JyiUROd2tmZa5A+dYbUR4m977ptTh6WpqYl/L/l0sgJZJK2yyEbNKvy2JA8\nrFbJ+szz4bhjpu0KAtx2AYSx0NVO97m33dzvy5beVqzhlCxxO9X1wPiVcgUbRZVSFQD+EcCfaa3P\nqrOitdYg/Xq+7dYppfYppfY5uaoFQRCEiacgCV0p5QO9zJ/WWjsVJk4rpcJa64hSKgwgb+p/rfUG\nABsAYM6cOTkv/VqWAM+cMRKY8zs1s96IYANcZm7ZXMoZ0hkxhsItL1FZsLWrL3HbvCyzth81EvSV\ny2l9H4uiiaTZR77fxvqLaR9rb1nstr25ez8A4MWXugEAPREz7lUrKWthwGN+dYMhkqqPdRnpeu23\nrgEAdLzXBgBIxo0tuXUuBUTFek3/ruzQkrlD7UxjJG5oonHUN8x320I1tTnbDEdLLe0vbV2YjiN0\nLRMwP8xVp+l+VFc1Azg7l4ufZwp1dWZsM0O03HvSdp/kDImchyWdsgKXWNBOZy1JZpBmA75qKw9G\nhmQTb5INpoOmfyxF042qgFVMgMvRXTB+T7EJIczfRNv1cbqJP04xGgAI8yStM1JOpt5ikDuTHA8j\nSuhKKQXgCQCHtdY/tlZtBXA/L98PYMu4RyMIgiCMmUIk9K8B+C6Ag0opJ8rkPwH4GwC/Uko9AOBj\nAHdPzhAFQRCEQhjxha613g1ADbF69XgH8EffvREAsHdvl9vWe5xqrPcNmCly41yamnTEaFryh//q\nLnfdscNkfKufP8+0HSV7rZ2LpLaO/J0jnaQ6GHzD1Cx1qKk1c/D5YVJZ+HzGdzsUouV4nPa/bLHx\n3g4EacITrjKqjkiU8qRUVRi1Q9ozyPugz0P7jF93GjSX7cmacQ9dmdCw+qbr3OVgJY2pNlzvtv36\ntV052wT91G/JYlIptb+/z13XxbU/7UlgiEeyZEGLaWMVSobT7doql5UryRBbUWmuc+dH5INfXW1S\nhQa4luIgq0GSWaNyyfL1SFlGUcfXPW1dkQznmYlzmGnaKpLhZT90e2yfnSa920U1RY6t429giC+H\nx9azsGF6uqhe/uAmc99r/fQ9+PlL+4bqLhSEeYZT2fHHwEikqCAIQplQ9FwujQ0kmvzoJ8bl0Imu\nvGGlkX43b/vwrO0efewFd/mar5HkcOpjE13Z00UGz9oGI+W3HaT1lVxc4WCbMZg6gYWNlqtfJknS\n3q9fNlKIU5i7tp4MrF7LqLZ3P0naQZ/JjdJQS/u78quWAa+XKh04kmaFz/xKt/XlRi4WYna69y4z\nYwmGqBxcR5epqNDT4yybCE1fkKTrPftyMzC6+7IcImtn070Kh42HqpNXpauLZli1dWbdbI4ADc8x\n1/RIB93HCmvGUlVN4x3k+UDSTuaS9vM6YzyqZJfElGU89XK+Fh9Hkdo1TDy+aWL5zAcbQQf4tifN\nKdlOli7OVctaothAvo4TyPJF9Oz+xUbzHXTGsWrJhHsrn2eY+ZeTRXQ8iIQuCIJQJsgLXRAEoUwo\nusrFX7Ugp23JYjLmNc03xsUlSygiLeChyd7eA8aIuugr5APd+eFzbtuxEzQFbz9R2DicgvDxuDFQ\nsjs3asNGPeBljUXXh2QU2rXzYM6+7lxj/NY3v0Lrv/JVY7RcuIKsXc/802sAgMZWs23btsLGey7B\ngFErBH00yCWLTTrTpnmc5rbXRPYZf2+3OkTOfu0E/I5BOG2pRA4epPNLJGjqGI0aw042Q/s9YSXz\n6u+nc29psZI6eWi8M5yLi8/NPpwudmItTtjls+SRLI/JiWENhozRNc2bpq3AtopKx9A9PUyOTs2Q\nkbLbuQq5SVaz2ByP5F4jZxxb2szztFSSf4yTKYwUFQRBEKY3RZfQ//I/PwUAaG1tctuee5Ukujtv\nMwa8tjaS/BZfSp/rrdyOtbXk5hj71PzCLeHKc3vbRjeeJbeY5YWULRYnuoyh0vGC7DlJkumKy03/\nMHtNBn3GGNnUSJ+PPm5yqNy4hmYe9ewF5rOKff/ROvrc/bJp6yxglhE9bSSleBddP5/fzCw8/Ovf\nONeSjLNkQDwVIek2n9vU4sal7nIgQNJ6R4cx+ia4eEUiS/v3pI2MsOsApee1M/EuuJjOvbbO5KpJ\nJCgStiJAiXZ9Vi4cH1uhvZYR1aldYe/XSSsxyDeoPmiMdX4fl6Cz8mZkplLELYCpS+I7evrOFHsE\nQqGIhC4IglAmyAtdEAShTCi6yqW7+zh/mrYQl7gJGtdt3LCK29g1PW7Z77q52lDgItO26Gr6tM18\njqbgBs7yWT/HrDtEw0ClVbbnALvd9hmbHhawnXahU+zIcpmu5XXBkEn6dTPnC+szWhjs6qCDBWbR\n/5b9Dk5Q6sJvmbZqLiz0kck4m8Obr27P2UnPaaNCWXU1RW16/eai7nv3AAAg3k/qmpSxRaJmBg2q\nNlzltvn9nIY2Y0460UnKgsZaUnHE40Z5kGUf65DHHLOpiQzYwaCpYzTIBs0sW6YHLeNlgDUjFQGT\nstfLibhsaSQUpGjUGB8/ETX3oCJMVtFQhYlYTTkql0xu1aipxFEbTXyFU+F8RCR0QRCEMqHoEvoq\nEhzx7dtN2yALaF1xI2HufJ0+OfASWzab/k0LSb5pXWbanKLuS0zZUHyDpd52DihNGKEPzSxJ77PK\nbDoF5Fu+YtqOHOZ9sNdko2VjTLINd9CS6L1sp+23PL92fUyfFdz/1Ntm3YXsvuazMuae4cTEfiMs\n57Dl2a3uchcLnyFr/drbKZL0SNdxty3aRylsv333NwEY10YAiPeTA91AwtyDzwao7UiHKVzhZ4k/\nzblW7OIec2dypGjYGEBr6+iCxfqNg156kAZ8IefC8Vnht06umPp6M7YMy7XBtBUBystBjgK2AmIR\n4IIcdi4XcHrdbJGzvw53+EJy+AiCjUjogiAIZULRJfQ7OAVJjxVR4UjodlH3Wzk574lP6HOZpevu\nIK9FpCxRxpG4DxmBFD0s9Q46Hn5GcISTnM+qoIZlLJnXmmSLCDltvO12q+pdF0vS9SbJIRq5X7fl\nPpl0xulI7da5X84xSZ3WOGZzbYreUxiSrjxeeC++aKKUqmtIMn7jLZO3pZEl8qCfxNkKS8c8u4Z0\n6H0RM43pPk5Tj4zlmhhkQ0dLC/lgRqNWnRPOchi0jCE1dTTNiJy2+rHk7OV+ydPmRJ3ydBVBI3Jn\nOZHJQNLUKHSE+gwXvXCCoABTji5ly7pVPH+JmPw/0w2RzIXRIhK6IAhCmSAvdEEQhDJhRJWLUioA\nYBcoTcYMAJu11o8opeYD2ARgNoD3AHxXa/270Q5gD6dCyVhGrFrH+Gf93Di2riO/pU+/5erXyBGX\nvZbqIvYefb5pZYadzaqQS9i+dswyXtayCuear5q2Q5xdt+tj09buuB86qWQsVUeGtQiVlspl5276\nDFslPZPOOB2tg7WP+ivoM25ZNNt2YFR85zbSY4VqjMW2k9Pb1jeYwTl5WPbvpzqpGctC2NpKA0kk\nzeCCPrpIjfNNoQPWqqC+gXRLwUpzI/s5J2y4zujHDh5u47GZtsoaOtmEl47VEzMuh/NY71ZVadQ2\nCS50Gk+a8QZ4H2nOm5utsR4QDz3mAZ+JLQ3wfmMRE/UqjJ7lzdUjdxKmjEIk9EEA12utlwBYCmCN\nUuoqAD8C8Hda6y+DtMAPTN4wBUEQhJEopASdhlsMCz7+0wCuB3Aft28E8EMAj412AP3sFZe1goh2\nsRvfPMtoGeZ+7d30GTG1KVwJt8qSjLmqGjKW+98gS8S7WTL3WYZVx0Nyn9U/fqSQM7Dgn8eonZjD\nGa+dJoWvZuVcHrcljffyDKTS/ql17HvD/PxWWoUonnnhWQBAxkqYX1tHU4S6WiO1L7yMgnzC4WsA\nGNdDAHhn71sAgD1vveO2LWmii3rddSZzZH+MrLfbXqaCIytXXu2um9tEU6G2/SYjZcM8ztljuRBe\nyMbQOBcUiVnBSXvepuO3HzY3Y4Al9FjC9Iv103IqzhfXyj6JFAcPBaxpIGeFfOT7IoeMh0f/9wZ3\neevruZlHhamlIB26UsrLBaL7AGwHKRw+1VpzLCBOAqgfYtt1Sql9Sql9yeT0SFUqCIJQjhT0Qtda\nZ7TWS0GOflcCaBlhE3vbDVrrVq11q+2+JgiCIEwso/JD11p/qpR6HcAKALOUUjNYSm8A0Dv81vlp\n5/wkvZZbsqNC6bN8t2tIO4DoMGqQmKl5gV2OisPKTxLnEQa5pkbSUo30jFa9kg8ed6xv+G7gNCYD\nnBY3ZdmVMqwOWvN109bG5zUwTI7V//DQg6b/e2TkrKwwPuQ1bGmOW5GfA456gjOJdH5kLkI4TBOu\nG37vGrftzdfIwvxO21tu25XLKTx37e1U3aD7Y3MT4knSX81vbHTbPBf4eTxmQpfhsM7Tx+kG2aqf\nDjbY4nPLMV8oOo7yatm1a9w2UbkUnxEldKXUl5RSs3j5QgA3ADgM4HUAd3K3+wFsmaxBCoIgCCNT\niIQeBrBRKeUF/QD8Smv9olKqHcAmpdRfATgA4ImxDCDh2O3y1RuwNDRWUODQ2BUPhknKnzxWwL7G\nwUzLRTHlzFuGGX/aFFNHL0vrrxgh2NykYeqT9ViS8dz5ZE2urDTRkn2c7vGdt02ymr2HaJuVl5MG\nrdEq+bft5ecBAK3LjJHzhm+sBgAc+MBMnfo44jOboRvZ9GVTqMTjJ8NktM8MvIZdKRNWefsMzxAS\nnDzHVs2FLqGpWc+HVtjwF+zal6mxAAAGPklEQVSuOMMyfDpG1kEnPaMV3uvUd6uwHijbaCoURKXH\nfMHe+c0YayUKk0ohXi4fALg8T/sxkD5dEARBmAZIpKggCEKZUPTkXPHhypxbaoqCVC72LHpwyF75\nYZ9w5Kvfaf/sDVOKMtBIn30HCjymYxe0fdTZoNo7kmH1HJ585nmz29lksrIjPx1D4xnrOjq+7nG+\nCZmMcfy/tIWym53uM8mrmhsuBQAs/OfNblvXcVLbpDgdbSplLryX00sFg0b9kUwleWzmZvk4OVio\nmvRNEcu/3MPT/Jomo8qJxUg1k7ETgVWyM38l9Q9YKpdMlm5a1kp3VREUlctZOEVIskO7Fj/6t4+4\nyy0rv8ZL06s26/mOSOiCIAhlgqJA0Klhzpw5et26dVN2PEEQhHJg/fr172mtW0fqJxK6IAhCmSAv\ndEEQhDJBXuiCIAhlgrzQBUEQyoQpNYoqpT4B8P9wtqNeKVKD0j6HUh8/UPrnUOrjB0r/HEpp/P9M\na/2lkTpN6QsdAJRS+wqx1k5nSv0cSn38QOmfQ6mPHyj9cyj18edDVC6CIAhlgrzQBUEQyoRivNA3\njNxl2lPq51Dq4wdK/xxKffxA6Z9DqY8/hynXoQuCIAiTg6hcBEEQyoQpfaErpdYopY4opY4qpR6a\nymOPBaXUXKXU60qpdqXUh0qp73F7tVJqu1Kqkz+rij3W4eAi3weUUi/y//OVUnv5PvxSKXVBscc4\nHEqpWUqpzUqpDqXUYaXUihK8B/+On6FDSqlnlFKB6XwflFI/V0r1KaUOWW15r7ki/p7P4wOl1LLi\njdwwxDn8N36OPlBK/V+nGhuv+wGfwxGl1DeKM+rxMWUvdK549D8B3ARgIYB7lVILp+r4Y+QLAN/X\nWi8EcBWAP+UxPwRgh9a6GcAO/n868z1Q2UCHHwH4O631l0F1kB4oyqgK56cAXtFatwBYAjqXkrkH\nSql6AA8CaNVaLwLV1roH0/s+PAlgzTltQ13zmwA08986AI9N0RhH4knknsN2AIu01l8B8BGAHwAA\nf6/vAXAZb/Mov7NKiqmU0K8EcFRrfUxr/TsAmwCsncLjjxqtdURrvZ+XB0AvknrQuDdyt40A7ijO\nCEdGKdUA4BYAj/P/CsD1ADZzl+k+/hCAa8AlDrXWv9Naf4oSugfMDAAXKqVmgIorRjCN74PWeheA\n/nOah7rmawE8pYm3QQXkw1Mz0qHJdw5a61e5sD0AvA0qcA/QOWzSWg9qrY8DOIoSrMg2lS/0epxd\nPuIkTImHaY9SqhFUim8vgDqttVP54RSAuiINqxB+AuA/wlQimA3gU+uhnu73YT6ATwD8A6uNHldK\nXYQSugda614AfwugB/QijwN4D6V1H4Chr3mpfrf/BYCXeblUz+EsxChaAEqpCgD/CODPtNaf2es0\nuQlNS1chpdStAPq01u8VeyzjYAaAZQAe01pfDkodcZZ6ZTrfAwBgXfNa0I/THAAXIVcVUFJM92s+\nEkqph0Eq1aeLPZaJZCpf6L0whd4Amur0TuHxx4RSygd6mT+ttX6Om087U0r+HGXBuCnjawBuV0p1\ng1Rc14P00bN46g9M//twEsBJrfVe/n8z6AVfKvcAAH4PwHGt9Sda6zSA50D3ppTuAzD0NS+p77ZS\n6g8B3Arg97Xx2y6pcxiKqXyhvwugmS37F4AMEFun8PijhvXNTwA4rLX+sbVqK4D7efl+AFumemyF\noLX+gda6QWvdCLre/6S1/n0ArwO4k7tN2/EDgNb6FIATSqlLuWk1gHaUyD1gegBcpZQK8jPlnEPJ\n3AdmqGu+FcAfsLfLVQDilmpmWqGUWgNSQd6utbYLqG4FcI9Syq+Umg8y8L5TjDGOC631lP0BuBlk\nWe4C8PBUHnuM410JmlZ+AOB9/rsZpIfeAaATwGsAqos91gLOZRWAF3l5AehhPQrgWQD+Yo9vhLEv\nBbCP78PzAKpK7R4AWA+gA8AhAP8HgH863wcAz4D0/WnQLOmBoa45AAXyYOsCcBDkzTNdz+EoSFfu\nfJ9/ZvV/mM/hCICbij3+sfxJpKggCEKZIEZRQRCEMkFe6IIgCGWCvNAFQRDKBHmhC4IglAnyQhcE\nQSgT5IUuCIJQJsgLXRAEoUyQF7ogCEKZ8P8Br1BEvEMMp9kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFt20jqmC1BS",
        "colab_type": "code",
        "outputId": "efb864e5-a72f-4e3b-c7aa-e1f1ba07fbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 1250 2500 3750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy_zKCcmC4x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LxII7KLC6am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpPQboMvJzJ_",
        "colab_type": "code",
        "outputId": "de0e1402-4b39-4d2f-86cc-ad11c13b3d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JznCNul3DyN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAJEUmzmC6Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1mWCTnFC6FL",
        "colab_type": "code",
        "outputId": "648e9259-592b-4173-e7de-0ac9c9be69bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow1_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.223968098435221\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.145406771309768\n",
            "\n",
            "Epoch : 3/20.. Training loss: 2.0536428373071214\n",
            "\n",
            "Epoch : 4/20.. Training loss: 2.002625030807302\n",
            "\n",
            "Epoch : 5/20.. Training loss: 2.003157511542115\n",
            "\n",
            "Epoch : 6/20.. Training loss: 2.012034755718859\n",
            "\n",
            "Epoch : 7/20.. Training loss: 1.9646853329260139\n",
            "\n",
            "Epoch : 8/20.. Training loss: 1.9681445918505704\n",
            "\n",
            "Epoch : 9/20.. Training loss: 1.976021728938139\n",
            "\n",
            "Epoch : 10/20.. Training loss: 1.9688404979585092\n",
            "\n",
            "Epoch : 11/20.. Training loss: 1.944679198385794\n",
            "\n",
            "Epoch : 12/20.. Training loss: 1.9650343852707102\n",
            "\n",
            "Epoch : 13/20.. Training loss: 1.9416142581384392\n",
            "\n",
            "Epoch : 14/20.. Training loss: 1.9205953139293044\n",
            "\n",
            "Epoch : 15/20.. Training loss: 1.9481337568427943\n",
            "\n",
            "Epoch : 16/20.. Training loss: 1.9069928730590433\n",
            "\n",
            "Epoch : 17/20.. Training loss: 1.933843523641176\n",
            "\n",
            "Epoch : 18/20.. Training loss: 1.9328880053532274\n",
            "\n",
            "Epoch : 19/20.. Training loss: 1.9037508194959616\n",
            "\n",
            "Epoch : 20/20.. Training loss: 1.9030695218074172\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMkQ2bFXDjsK",
        "colab_type": "code",
        "outputId": "1d7e0ab6-55d5-4386-ea91-0b01916b7fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 23 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtdgk34vDjby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma9NzU-NDqxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow1_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[2000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDI7v6aXDqmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow1.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB_NxoxYEC_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target1.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19pUfMBLEC1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzqcQS7Emf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbBWew1OEsTZ",
        "colab_type": "code",
        "outputId": "4cb2b81b-8395-4052-cc1c-b5f2adac08be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 2500 and No.of test data 625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxZCTsrvE2Ns",
        "colab_type": "code",
        "outputId": "94af2b5c-a211-4741-8983-8f55c0ab51d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack1_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06936240129470825\n",
            "Training loss: 0.06934072761535645\n",
            "Training loss: 0.06935013334751129\n",
            "Training loss: 0.06933759889602661\n",
            "Training loss: 0.06934542911052703\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VicAcUcE6ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOHVYdLrE8-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[500:2500]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es5JyqLnFBE0",
        "colab_type": "code",
        "outputId": "032fad26-8054-4ef3-fa3e-a7c92b62f50e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "if((tp+fp)!=0):\n",
        "  pre = tp/(tp+fp)\n",
        "if((tp+fn)!=0):\n",
        "  rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 750, TN : 0, FP : 1250, FN : 0\n",
            "Precision 37.5\n",
            "Recall 100.0\n",
            "F1 Score 54.54545454545454\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}